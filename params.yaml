base:
  data_source_path: artifacts/data.csv
  data_dest_path: artifacts1/data.csv
  train_path: artifacts1/train.csv
  test_path: artifacts1/test.csv
  test_size: 0.25


params:
  Decision_Tree:
      criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
      splitter: ['best','random']
      max_features: ['sqrt','log2']
                
  Random_Forest:
      # criterion: ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']
      max_features: ['sqrt','log2']
      n_estimators: [8,16,32,64,128,256]

  GradientBoost:
    # loss: ['squared_error', 'huber', 'absolute_error', 'quantile']
    # learning_rate: [.1,.01,.05,.001]
    # subsample: [0.6,0.7,0.75,0.8,0.85,0.9]
    criterion: ['squared_error', 'friedman_mse']
    max_features: ['sqrt','log2']
    n_estimators: [8,16,32,64,128,256]

  XGBoost:
    learning_rate: [.1,.01,.05,.001]
    n_estimators: [8,16,32,64,128,256]

  CatBoost:
    depth: [6,8,10]
    learning_rate: [0.01, 0.05, 0.1]
    iterations: [30, 50, 100]
              
  AdaBoost:
    learning_rate: [.1,.01,0.5,.001]
    loss: ['linear','square','exponential']
    n_estimators: [8,16,32,64,128,256]